<!DOCTYPE html>
<html>
  <head>
    <title>SQLite C API</title>
    <meta charset="UTF-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <link rel="stylesheet" type="text/css" href="stylesheet.en.css"/>
    <!--
    <meta name="keywords" content="KW1, KW2, KW3"/>

    <meta name="author" content="AUTHOR"/>
    <meta name="description" content="A_DESCRIPTION"/>
    <meta name="FIELD_NAME" content="FIELD_VALUE"/>
    -->
  </head>
  <body lang="en" class="computing">
    <nav>
    <!--
      <p><a href="A_PAGE.html">LINK_TEXT</a></p>
      <p><a href="ANOTHER_PAGE.html">LINK_TEXT</a></p>
      <p><a rel="prev" href="PREVIOUS_PAGE.html">LINK_TEXT</a></p>
      <p><a rel="next" href="NEXT_PAGE.html">LINK_TEXT</a></p>
      -->
      <div>
        <p><a rel="next" href="sqlite.c-core-api.html">SQLite C Core API</a></p>
        <p><a            href="sqlite.c-extension-api.html">SQLite C Extension API</a></p>
      </div>
      <div>
        <p><a            href="sqlite.sqlite3.html">Running <code>sqlite3</code></a></p>
        <p><a            href="sqlite.sqlite3.ref.html">Command Line Shell For SQLite</a></p>
        <p><a            href="sqlite.data-types.html">SQLite Data Types</a></p>
        <p><a            href="sqlite.tables.html">Tables in SQLite</a></p>
        <p><a rel="prev" href="sqlite.html">SQLite: A Light OpenSource Relational Database (RDBMS and Library)</a></p>
      </div>
      <div>
        <p><a            href="c.html">The C   Programming Language</a></p>
        <p><a            href="cpp.html">The C++ Programming Language</a></p>
      </div>
      <div>
        <p><a            href="relational-database.html">Relational DataBases</a></p>
        <p><a            href="sql.html">Structured Query Language (SQL)</a></p>
      </div>
      <div>
        <p><a href="special-relational-tables.html">Special Relational Tables</a></p>
      </div>
    </nav>

    <main>
      <h1>SQLite C API</h1>
      <p>Key to understanding SQLite is knowing how the API works. So, this page starts with a conceptual introduction to the API, illustrating its major data structures, its general design, and its major functions. It also looks at some of the major SQLite subsystems that play important roles in query processing. Beyond just knowing what functions do what, we&apos;ll also look above the API, seeing how everything operates in terms of transactions. Everything involving a SQLite database is done within the context of a transaction. Then you need to look beneath the API, seeing how transactions work in terms of locks. Locks can cause problems if you don&apos;t know how they operate. By understanding locks, not only can you avoid potential concurrency problems, but you can also optimize your queries by controlling how your program uses them.</p>
      <p>Finally, you have to understand how all of these things apply to writing code. The last section brings all three topics—the API, transactions, and locks—together and looks at different examples of good and bad code. It specifically identifies scenarios that could cause problems and provides some insight on how to address them. With these things in order, you will be well on your way to conquering the C API and the API of any language extension.</p>

      <section>
        <h2>The API</h2>
        <p>Functionally, the SQLite API can be separated into two general parts: the core API and the extension API.</p>
        <p>The core API consists all the functions used to perform basic database operations: connecting to the database, processing SQL, and iterating through results. It also includes various utility functions that help with tasks such as string formatting, operational control, debugging, and error handling.</p>
        <p>The extension API offers different ways to extend SQLite by creating your own user-defined SQL extensions, which you can integrate into SQLite&apos;s SQL dialect.</p>

          <h3>The Principal Data Structures</h3>
          <p>As discussed in <a href="sqlite.html#architecture">Architecture</a>, there are many components in SQLite—parser, tokenizer, virtual machine, and so on. But from a programmer&apos;s point of view, the main things to know about are connections, statements, the B-tree, and the pager. These objects collectively address the three principal things you must know about SQLite to write good code: the API, transactions, and locks.</p>
          <p>Technically, the B-tree and pager are not part of the API; they are off-limits. But they play a critical role in transactions and locks. We will explore their involvement in these matters here in this section and later in the section on Transactions.</p>

            <h4>Connections and Statements</h4>
            <p>The two fundamental data structures in the API associated with query processing are the connection and the statement. In most language extensions, you will see both a connection object and a statement object, which are used to execute queries. In the C API, they correspond directly to the <code>sqlite3</code> and <code>sqlite3_stmt</code> handles, respectively. Every major operation in the API is done using one of these two structures.</p>
            <p>A <dfn>connection</dfn> represents a single connection to a database as well as a single transaction context.</p>
            <p>Statements are derived from connections. That is, every statement has an associated connection object. A <dfn>statement</dfn> represents a single compiled SQL statement. Internally, it is expressed in the form of <a href="sqlite.html#VDBE">VDBE</a> byte code—a program that when executed will carry out the SQL command. Statements contain everything needed to execute a command. They include resources to hold the state of the VDBE program as it is executed in a stepwise fashion, B-tree cursors that point to records on disk, and other things such as bound parameters, which are addressed later in the section <cite>Parameter Binding</cite>. Although they contain many different things, you can simply think of them as cursors with which to iterate through a result set, or as opaque handles referencing a single SQL command.</p>

            <h4>The B-tree and Pager</h4>
            <p>Each connection can have multiple database objects—one main database followed by any attached databases. Each database object has one B-tree object, which in turn has one pager object.</p>
            <p>Statements use their connection&apos;s B-tree and pager objects to read and write data to and from the database. Statements that read the database iterate over B-trees using cursors. <dfn>Cursors</dfn> iterate over records, and records are stored in pages. As a cursor traverses records, it also traverses pages. For a cursor to access a page, it must first be loaded from disk into memory. This is the pager&apos;s job. Whenever the B-tree needs a particular page in the database, it asks the pager to fetch it from disk. The pager then loads the page into its page cache, which is a memory buffer. Once it is in the page cache, the B-tree and its associated cursor can get to the records inside the page.</p>
            <p>If the cursor modifies the page, then the pager must also take special measures to preserve the original page in the event of a transaction rollback. Thus, the pager is responsible for reading and writing to and from the database, maintaining a memory cache or pages, and managing transactions. In addition to this, it manages locks and crash recovery. All of these responsibilities are covered later in <cite>Transactions</cite>.</p>
            <p>There are two things you should know about connections and transactions in general. First, when it comes to any operation on the database, a connection always operates under a transaction. Second, a connection never has more than one transaction open at a time. That means all statements derived from a given connection operate within the same transaction context. If you want the two statements to run in separate transactions, then you have to use multiple connections—one connection for each transaction context.</p>

          <h3>The Core API</h3>
          <p>As mentioned earlier, the core API is concerned with executing SQL commands. It is made of various functions for performing queries as well as various utility functions for managing other aspects of the database. There are two essential methods for executing SQL commands: <a href="sqlite.c-core-api.html#prepared-queries">prepared queries</a> and wrapped queries. <a href="sqlite.c-core-api.html#prepared-queries">Prepared queries</a> are the way in which SQLite ultimately executes all commands, both in the API and internally. It is a three-phase process consisting of preparation, execution, and finalization. There is a single API function associated with each phase. Associated with the execution phase are functions with which to obtain record and column information from result sets.</p>
          <p>In addition to the standard query method, there are two <a href="sqlite.c-core-api.html#wrapped">wrapper functions</a>, which wrap the three phases into a single function call. They provide a convenient way to execute a SQL command all at once. These functions are just a few of the many miscellaneous utility functions in the API. We will look at all of the query methods along with their associated utility functions in this section. Before we do however, let&apos;s first look at how to connect to a database.</p>

            <h4>Connecting to a Database</h4>
            <p>Connecting to a database involves little more than opening a file. Every SQLite database is stored in a single operating system file—one database to one file. The function used to connect, or open, a database in the C API is <code>sqlite3_open()</code> and is basically just a system call for opening a file. SQLite can also create in-memory databases. In most extensions, if you use <code>:memory:</code> or an empty string as the name for the database, it will create the database in RAM. The database will be accessible only to the connection that created it (it cannot be shared with other connections). Furthermore, the database will only last for the duration of the connection. It is deleted from memory when the connection closes.</p>
            <p>When you connect to a database on disk, SQLite opens a file, if it exists. If you try to open a file that doesn&apos;t exist, SQLite will assume that you want to create a new database. In this case, SQLite doesn&apos;t immediately create a new operating system file. It will create a new file only if you put something into the new database—create a table or view or other database object. If you just open a new database, do nothing, and close it, SQLite does not bother with creating a database file—it would just be an empty file anyway.</p>
            <p>There is an important reason for not creating a new file right away. Certain database options, such as encoding, page size, and autovacuum, can be set only before you create a database. By default, SQLite uses a 1,024-byte page size. However, you can use different page sizes ranging from 512 to 32,768 bytes by powers of 2. You might want to use different page sizes for performance reasons. For example, setting the page size to match the operating system&apos;s page size can make I/O more efficient. Larger page sizes can help with applications that deal with a lot of binary data. You set the database page size using the <code>page_size</code> pragma.</p>
            <p>Encoding is another permanent database setting. You specify a database&apos;s encoding using the <code>encoding</code> pragma, which can be UTF-8, UTF-16, UTF-16le (little endian), and UTF-16be (big endian). Finally there is <var>autovacuum</var>, which you set with the <code>auto_vacuum</code> pragma. When a transaction deletes data from a database, SQLite&apos;s default behavior is to keep the deleted pages around for recycling. The database file remains the same size. To free the pages, you must explicitly issue a <code>vacuum</code> command to reclaim the unused space. The autovacuum feature causes SQLite to automatically shrink the database file when data is deleted. This feature is often more useful in embedded applications where storage is a premium.</p>
            <p>Once you open a database—file or memory—it will be represented internally by an opaque <code>sqlite3</code> connection handle. This handle represents a single connection to a database. Connection objects in extensions abstract this handle and sometimes implement methods that correspond to API functions that take the handle as an argument.</p>

            <h4>Executing Prepared Queries</h4>
            <p>As stated earlier, the prepared query method is the actual process by which SQLite executes all SQL commands. Executing a SQL command is a three-step process:</p>
            <ul>
              <li><strong>Preparation:</strong> The parser, tokenizer, and code generator prepare the SQL statement by compiling it into VDBE byte code. In the C API, this is performed by the <code>sqlite3_prepare_v2()</code> function, which talks directly to the compiler. The compiler creates a <code>sqlite3_stmt</code> handle (statement handle) that contains the byte code and all other resources needed to execute the command and iterate over the result set (if the command produces one).</li>
              <li><strong>Execution:</strong> The VDBE executes the byte code. Execution is a stepwise process. In the C API, each step is initiated by <code>sqlite3_step()</code>, which causes the VDBE to step through the byte code. The first call to <code>sqlite3_step()</code> usually acquires a lock of some kind, which varies according to what the command does (reads or writes). For <code>SELECT</code> statements, each call to <code>sqlite3_step()</code> positions the statement handle&apos;s cursor on the next row of the result set. For each row in the set, it returns <code>SQLITE_ROW</code> until it reaches the end, whereupon it returns <code>SQLITE_DONE</code>. For other SQL statements (insert, update, delete, and so on), the first call to <code>sqlite3_step()</code> causes the VDBE to process the entire command.</li>
              <li><strong>Finalization:</strong> The VDBE closes the statement and deallocates resources. In the C API, this is performed by <code>sqlite3_finalize()</code>, which causes the VDBE to terminate the program, freeing resources and closing the statement handle.</li>
            </ul>
            <p>Each step—preparation, execution, finalization—corresponds to a respective statement handle state—prepared, active, or finalized. Prepared means that all necessary resources have been allocated and the statement is ready to be executed, but nothing has been started. No lock has been acquired, nor will a lock be acquired until the first call to <code>sqlite3_step()</code>. The active state starts with the first call to <code>sqlite3_step()</code>. At that point, the statement is in the process of being executed, and some kind of lock is in play. Finalized means that the statement is closed and all associated resources have been freed.<!-- Figure 5-2 shows these steps and states.--></p>

            <aside>
              <h4>Temporary Storage</h4>
              <p>Temporary storage is an important part of query processing. SQLite occasionally needs to store intermediate results produced in the process of executing commands—for instance, when results need to be sorted for an order by clause or rows in one table are joined with rows in another table. This information is often stored in temporary storage. Temporary storage is kept either in RAM or in a file. Although SQLite has suitable defaults for all platforms, you may want to control how and where it uses this storage. The <code>temp_store</code> pragma lets you specify whether to use RAM or file-based storage. If you use file-based storage, you can use the <code>temp_store_directory</code> pragma to specify where the storage file is created.</p>
            </aside>

            <h4>Using Parameterized SQL</h4>
            <p>SQL statements can contain parameters. Parameters are placeholders in which values may be provided (or <q>bound</q>) at a later time after compilation. The following statements are examples of parameterized queries:</p>
            <pre>insert into foods (id, name) values (?,?);
insert into episodes (id, name) (:id, :name);</pre>
            <p>These statements represent two forms of parameter binding: <dfn>positional</dfn> and <dfn>named</dfn>. The first command uses positional parameters, and the second command uses named parameters.</p>
            <p>Positional parameters are defined by the position of the question mark in the statement. The first question mark has position 1, the second 2, and so on. Named parameters use actual variable names, which are prefixed with a colon. When <code>sqlite3_prepare_v2()</code> compiles a statement with parameters, it allocates placeholders for the parameters in the resulting statement handle. It then expects values to be provided for these parameters before the statement is executed. If you don&apos;t bind a value to a parameter, SQLite will use NULL as the default when it executes the statement.</p>
            <p>The advantage of parameter binding is that you can execute the same statement multiple times without having to recompile it. You just reset the statement, bind a new set of values, and reexecute. This is where resetting rather than finalizing a statement comes in handy: it avoids the overhead of SQL compilation. By resetting a statement, you are reusing the compiled SQL code. You completely avoid the tokenizing, parsing, and code generation overhead. Resetting a statement is implemented in the API by the <code>sqlite3_reset()</code> function.</p>
            <p>The other advantage of parameters is that SQLite takes care of escaping the string values you bind to parameters. For example, if you had a parameter value such as <q>Kenny's Chicken</q>, the parameter binding process will automatically convert it to <q>Kenny''s Chicken</q>—escaping the single quote for you, helping you avoid syntax errors and possible SQL injection attacks (covered in the section <cite>Formatting SQL Statements</cite>). The following pseudocode illustrates the basic process of using bound parameters:</p>
            <pre>db = open('foods.db')
stmt = db.prepare('insert into episodes (id, name) values (:id, :name)')
stmt.bind('id', '1')
stmt.bind('name', 'Soup Nazi')
stmt.step()
# Reset and use again
stmt.reset()
stmt.bind('id', '2')
stmt.bind('name', 'The Junior Mint')
# Done
stmt.finalize()
db.close()</pre>
            <p>Here, <code>reset()</code> simply deallocates the statement&apos;s resources but leaves its VDBE byte code and parameters intact. The statement is ready to run again without the need for another call to <code>prepare()</code>. This can significantly improve performance of repetitive queries such as this because the compiler is not invoked.</p>

            <h4>Executing Wrapped Queries</h4>
            <p>As mentioned earlier, there are two very useful utility functions that wrap the prepared query process, allowing you to execute SQL commands in a single function call. One function—<code><a href="sqlite.c-core-api.html#sqlite3_exec">sqlite3_exec()</a></code>—is typically for queries that don&apos;t return data. The other—<code><a href="sqlite.c-core-api.html#sqlite3_get_table">sqlite3_get_table()</a></code>—is typically for queries that do. In many language extensions, you will see analogs to both functions. Most extensions refer to the first method simply as <code>exec()</code> and the second as just <code>get_table()</code>.</p>
            <p>The <code>exec()</code> function is a quick and easy way to execute insert, update, and delete statements or DDL statements for creating and destroying database objects. It works straight from the database connection, taking a <code>sqlite3</code> handle to an open database along with a string containing one or more SQL statements. That&apos;s right; <code>exec()</code> is capable of processing a string of multiple SQL statements delimited by semicolons and running them all together.</p>
            <p>Internally, <code>exec()</code> parses the SQL string, identifies individual statements, and then processes them one by one. It allocates its own statement handles and prepares, executes, and finalizes each statement. If multiple statements are passed to it and one of them fails, <code>exec()</code> terminates execution on that command, returning the associated error code. Otherwise, it returns a success code. The following pseudocode illustrates conceptually how <code>exec()</code> works in an extension:</p>
            <pre>db = open('foods.db')
db.exec("insert into episodes (id, name) values (1, 'Soup Nazi')")
db.exec("insert into episodes (id, name) values (2, 'The Fusilli Jerry')")
db.exec("begin; delete from episodes; rollback")
db.close()</pre>
            <p>Although you can also use <code>exec()</code> to process records returned from <code>SELECT</code>, it involves subtle methods for doing so that are generally supported only by the C API.</p>
            <p>The second query function, <code>sqlite3_get_table()</code>, is somewhat of a misnomer because it is not restricted to just querying a single table. Rather, its name refers to the tabular results of a select query. You can certainly process joins with it just as well. In many respects, <code>get_table()</code> works in the same way as <code>exec()</code>, but it returns a complete result set in memory. This result set is represented in various ways depending on the extension. The following pseudocode illustrates how it is typically used:</p>
            <pre>db = open('foods.db')
table = db.get_table("select * from episodes limit 10")

for i=0; i &lt; table.rows; i++
  for j=0; j &lt; table.cols; j++
    print table[i][j]
  end
end

db.close()</pre>
            <p>The upside of <code>get_table()</code> is that it provides a one-step method to query and get results. The downside is that it stores the results completely in memory. So, the larger the result set, the more memory it consumes. Not surprisingly, then, it is not a good idea to use <code>get_table()</code> to retrieve large result sets. The prepared query method, on the other hand, holds only one record (actually its associated database page) in memory at a time, so it is much better suited for traversing large result sets.</p>
            <p>Notice that although these functions buy you convenience, you also lose a bit of control simply by not having access to a statement handle. For example, you can&apos;t use parameterized SQL statements with either of them. So, they are not going to be as efficient for repetitive tasks that could benefit from parameters. Also, the API includes functions that work with statement handles that provide lots of information about columns in a result set—both data and metadata. These are not available with wrapped queries either. Wrapped queries have their uses, to be sure. But prepared queries do as well.</p>

            <h4>Handling Errors</h4>
            <p>The previous examples are greatly oversimplified to illustrate the basic parts of query processing. In real life, you always have to consider the possibility of errors. Almost every function you have seen so far can encounter errors of some sort. Common error codes you need to be prepared to handle include <code>SQLITE_ERROR</code> and <code>SQLITE_BUSY</code>. The latter error code refers to busy conditions that arise when a connection can&apos;t get a lock. Busy conditions are addressed in the <cite>Transactions</cite> section<!--, while schema errors are covered in detail in Chapter 6-->.</p> <p>With regard to general errors, the API provides the return code of the last-called function with the <code>sqlite3_errcode()</code> function. You can get more specific error information using the <code>sqlite3_errmsg()</code> function, which provides a text description of the last error. Most language extensions support this function in some way or another.</p>
            <p>With this in mind, each call in the previous example should check for the appropriate errors using something like the following:</p>
            <pre># Check and report errors
if db.errcode() != SQLITE_OK
  print db.errmsg(stmt)
end</pre>
            <p>In general, error handling is not difficult. The way you handle any error depends on what exactly you are trying to do. The easiest way to approach error handling is the same as with any other API—read the documentation on the function you are using and code defensively.</p>

            <h4>Formatting SQL Statements</h4>
            <p>Another nice convenience function you may see some extensions support is <code>sqlite3_mprintf()</code>. It is a variant of the standard C library <code>sprintf()</code>. It has special substitutions that are specific to SQL that can be very handy. These substitutions are denoted <code>%q</code> and <code>%Q</code>, and they escape SQL-specific values. <code>%q</code> works like <code>%s</code> in that it substitutes a null-terminated string from the argument list. But it also doubles every single-quote character, making your life easier and helping guard against SQL injection attacks (see the sidebar <cite><a href="#sql-injection-attacks">SQL Injection Attacks</a></cite>). Here&apos;s an example:</p>
            <pre>char* before = "Hey, at least %q no pig-man.";
char* after = sqlite3_mprintf(before, "he&apos;s");</pre>
            <p>The value after produced here is <q>Hey, at least he''s no pig-man</q>. The single quote in <q>he&apos;s</q> is doubled, making it acceptable as a string literal in a SQL statement. The <code>%Q</code> formatting does everything <code>%q</code> does, but it additionally encloses the resulting string in single quotes. Furthermore, if the argument for <code>%Q</code> is a <code>NULL</code> pointer (in C), it produces the string <code>NULL</code> without single quotes. For more information, see the <code>sqlite3_mprintf()</code> documentation in the C API reference in Appendix B.</p>
            <aside id="sql-injection-attacks">
              <h5>SQL Injection Attacks</h5>
              <p>If your application relies on any user input with which to construct SQL statements, you could be vulnerable to a SQL injection attack. If you are not careful to filter user input, it could be possible for someone to craft input that could alter the SQL statement, injecting a new SQL statement into the string. For example, say your program uses user input to fill in the value of the following SQL statement:</p>
              <pre>select * from foods where name='%s';</pre>
              <p>You replace the %s with whatever the user supplies. If users have any knowledge of your database, they could provide input that can dramatically alter the SQL statement. For example, say the user were to provide the following string value for the name input:</p>
              <pre>nothing' limit 0; select name from sqlite_master where name='%</pre>
              <p>After substituting the user&apos;s input into your SQL statement, the new statement turns into two statements:</p>
              <pre>select * from foods where name='nothing' limit 0;
select name from sqlite_master where name='%';</pre>
              <p>The first statement will return nothing, and the second will return the names of all objects in your database. Granted, the odds of this happening require quite a bit of knowledge on the attacker&apos;s part, but it is nevertheless possible. Some major (commercial) web applications have been known to keep SQL statements embedded in their JavaScript, which can provide plenty of hints about the database being used. In the previous example, all a malicious user has to do now is insert drop table statements for every table found in <code>sqlite_master</code>, and you could find yourself fumbling through backups.</p>
            </aside>

          <h3>Operational Control</h3>
          <p>The API includes a variety of commands that allow you to monitor, control, or generally limit what can happen in a database. SQLite implements them in the form of filters or callback functions that you can register to be called for specific events. There are three <q>hook</q> functions: <code>sqlite3_commit_hook()</code>, which monitors transaction commits on a connection; <code>sqlite3_rollback_hook()</code>, which monitors rollbacks; and <code>sqlite3_update_hook()</code>, which monitors changes to rows from insert, update, and delete operations.</p>
          <aside>Note The forthcoming release of SQLite 3.7 will include many new features, one of which is the <dfn>Write Ahead Log</dfn> (WAL). With this, a further type of hook named <code>wal_hook()</code> will be implemented. This is a little different to the hooks discussed here.<!-- More details on WAL will be covered in Chapter 11.--></aside>
          <p>These hooks are called at runtime—while a command is executed. Each hook allows you to register a callback function on a connection-by-connection basis and lets you provide some kind of application- specific data to be passed to the callback as well. The general use of operational control functions is as follows:</p>
          <pre>def commit_hook(cnx)
  log('Attempted commit on connection %x', cnx)
  return -1
end
db = open('foods.db')
db.set_commit_hook(rollback_hook, cnx)
db.exec("begin; delete from episodes; rollback")
db.close()</pre>
          <p>A hook&apos;s return value has the power to alter the event in specific ways, depending on the hook. In this example, because the commit hook returns a nonzero value, the commit will be rolled back.</p>
          <p>Additionally, the API provides a very powerful compile time hook called <code>sqlite3_set_authorizer()</code>. This function provides you with fine-grained control over almost everything that happens in the database as well as the ability to limit both access and modification on a database, table, and column basis.<!-- This function is covered in detail in Chapter 6.--></p>


          <h3>Using Threads</h3>
          <p>SQLite has a number of functions for using it in a multithreaded environment. With version 3.3.1, SQLite introduced a unique operational mode called <dfn>shared cache mode</dfn>, which is designed for multithreaded embedded servers. This model provides a way for a single thread to host multiple connections that share a common page cache, thus lowering the overall memory footprint of the server. It also employs a different concurrency model. Included with this feature are various functions for managing memory and fine-tuning the server. This operational mode is explained further later in the section <cite>Shared Cache Mode”</cite><!-- and in full detail in Chapter 6-->.</p>

      </section>

      <section>
        <h2>The Extension API</h2>
        <p>The extension API in the SQLite C API offers support for user-defined functions, aggregates, and collations. A <dfn>user-defined function</dfn> is a SQL function that maps to some handler function that you implement in C or another language. When using the C API, you implement this handler in C or C++. In language extensions, you implement the handler in the same language as the extension.</p>
        <p>User-defined extensions must be registered on a connection-by-connection basis as they are stored in program memory. That is, they are not stored in the database, like stored procedures in larger relational database systems. They are stored in your program. When your program or script starts up, it is responsible for registering the desired user-defined extensions for each connection that it intends to use them.</p>

          <h3>Creating User-Defined Functions</h3>
          <p>Implementing a user-defined function is a two-step process. First, you write the handler. The handler does something that you want to perform from SQL. Next, you register the handler, providing its SQL name, its number of arguments, and a pointer (or reference) to the handler.</p>
          <p>For example, say you wanted to create a special SQL function called <code>hello_newman()</code>, which returns the text <q>Hello Jerry</q>. In the SQLite C API, you would first create a C function to implement this, such as the following:</p>
          <pre>void hello_newman(sqlite3_context* ctx, int nargs, sqlite3_value** values)
{
  /* Create Newman's reply */
  const char *msg = "Hello Jerry";
  /* Set the return value.*/
  sqlite3_result_text(ctx, msg, strlen(msg), SQLITE_STATIC);
}</pre>
          <p>Don&apos;t worry if you don&apos;t know C or the C API. This handler just returns <q>Hello Jerry</q>. Next, to actually use it, you register this handler using the <code>sqlite3_create_function()</code> (or the equivalent function in your language):</p>
          <pre>sqlite3_create_function(db, "hello_newman", 0, hello_newman);</pre>
          <p>The first argument (<var>db</var>) is the database connection. The second argument is the name of the function as it will appear in SQL, and the third argument means that the function takes zero arguments. (If you provide -1, then it means that the function accepts a variable number of arguments.) The last argument is a pointer to the <code>hello_newman()</code> C function, which will be called when the SQL function is called.</p>
          <p>Once registered, SQLite knows that when it encounters the SQL function <code>hello_newman()</code>, it needs to call the C function <code>hello_newman()</code> to obtain the result. Now, you can execute <code>select hello_newman()</code> within your program, and it will return a single row with one column containing the text <q>Hello Jerry</q>. As mentioned before<!--in Chapter 4-->, user-defined functions are a handy way to implement specialized domain constraints by embedding them in check constraints.</p>

          <h3>Creating User-Defined Aggregates</h3>
          <p>Aggregate functions are functions that are applied to all records in a result set and compute some kind of aggregate value from them. <code>sum()</code>, <code>count()</code>, and <code>avg()</code> are examples of standard SQL aggregate functions in SQLite.</p>
          <p>Implementing user-defined aggregates is a three-step process in which you register the aggregate, implement a step function to be called for each record in the result set, and implement a finalize function to be called after record processing. The finalize function allows you to compute the final aggregate value and do any necessary cleanup.</p>
          <p>The following is an example of implementing a simple <code>SUM()</code> aggregate called <var>pysum</var> in one of the SQLite Python extensions:</p>
          <pre>connection=apsw.Connection("foods.db")

def step(context, *args):
  context['value'] += args[0]

def finalize(context):
  return context['value']

def pysum():
  return ({'value' : 0}, step, finalize)

connection.createaggregatefunction("pysum", pysum)

c = connection.cursor()
print c.execute("select pysum(id) from foods").next()[0]</pre>
          <p>The <code>createaggregatefunction()</code> function registers the aggregate, passing in the <code>step()</code> function and the finalize function. SQLite passes <code>step()</code> a context, which it uses to store the intermediate value between calls to <code>step()</code>. In this case, it is the running sum. SQLite calls <code>finalize()</code> after it has processed the last record. Here, <code>finalize()</code> just returns the aggregated sum. SQLite automatically takes care of cleaning up the context.</p>

          <h3>Creating User-Defined Collations</h3>
          <p>Collations define how string values are compared. User-defined collations therefore provide a way to create different text comparison and sorting methods. This is done in the API by the <code>sqlite3_create_collation()</code> function. SQLite provides three default collations: <code>BINARY</code>, <code>NOCASE</code>, and <code>RTRIM</code>. <code>BINARY</code> compares string values using the C function <code>memcmp()</code> (which for all intents and purposes is case sensitive). <code>NOCASE</code> is just the opposite—its sorting is case insensitive. The <code>RTRIM</code> collation works like <code>BINARY</code> except that it ignores trailing spaces.</p>
          <p>User-defined collations are especially helpful for locales that are not well served by the default <code>BINARY</code> collation or those that need support for UTF-16. They can also be helpful in specific applications such as sorting date formats that don&apos;t lend themselves to both lexicographical and chronological order.<!-- Chapter 7 illustrates implementing a user-defined collation to sort Oracle dates natively in SQLite.--></p>

      </section>

      <section>
        <h2>Transactions</h2>
        <p>By now you should have a picture of how the API is laid out. You&apos;ve seen different ways to execute SQL commands along with some helpful utility functions. Executing SQL commands, however, involves more than just knowing what&apos;s in the API. Transactions and locks are closely intertwined with query processing. Queries are always performed within transactions, transactions involve locks, and locks can cause problems if not managed properly. You can control both the type and duration of locks by how you use SQL and the way you write code.</p>
        <p><!--Chapter 4 illustrated a specific scenario where deadlocks can arise just by the way that two connections manage transactions through SQL alone. -->As a programmer, you will have another variable to juggle—code—which can contain multiple connections in multiple states with multiple statement handles on multiple tables at any given time. All it takes is a single statement handle, and your code may be holding an <code>EXCLUSIVE</code> lock without you even realizing it, preventing other connections from getting anything done.</p>
        <p>That is why it is critical that you have good grasp of how both transactions and locks work and how they relate to the various API functions used to perform queries. Ideally, you should be able to look at the code you write and tell what transaction states it will be in or at least be able to spot potential problems. In this section, we will explore the mechanics behind transactions and locks and in the next section observe them at work in actual code.</p>

          <h3>Transaction Life Cycles</h3>
          <p>There are a couple of things to consider with code and transactions. First there is the issue of knowing which objects run under which transactions. Next there is the question of duration—when does a transaction start and when does it end, and at what point does it start to affect other connections? The first question relates directly to the API. The second relates to SQL in general and SQLite&apos;s implementation in particular.</p>
          <p>As you know, multiple statement handles can be allocated from a single connection.<!-- As shown in Figure 5-2,--> Each connection has exactly one B-tree and one pager object associated with it per database. The pager plays a bigger role than the connection in this discussion because it manages transactions, locks, the memory cache, and crash recovery—all of which will be covered in the next few sections. You could just as easily say that the connection object handles all of this, but in reality it is the pager within it. The important thing to remember is that when you write to the database, you do so with one connection, one transaction at a time. Thus, all statement objects run within the single transaction context of the connections from which they are derived. This answers the first question.</p>
          <p>As for the second question, transaction duration (or the transaction life cycle) is as short as a single statement, or as long as you like—until you say stop. By default, a connection operates in <dfn>autocommit mode</dfn>, which means that every command you issue runs under a separate transaction. Conversely, when you issue a <code>begin</code>, the transaction endures until you call either a <code>COMMIT</code> or a <code>rollback</code>, or until one of your SQL commands causes a constraint violation that results in a rollback. The next question is how transactions relate to locks.</p>

          <h3>Lock States</h3>
          <p>For the most part, lock duration shadows transaction duration. Although the two don&apos;t always start together, they do always finish together. When you conclude a transaction, you free its associated lock. A better way of saying this is that a lock is never released until its associated transaction concludes or, in the worse case, the program crashes. And if the program or system crashes, the transaction doesn&apos;t conclude, in which case there is still an implicit lock on the database that will be resolved by the next connection to access it. This is covered later in the sidebar <cite>Locking and Crash Recovery</cite>.</p>
          <p>There are five different locks states in SQLite, and a connection is always in one of them no matter what it&apos;s doing.<!-- Figure 5-3 shows SQLite&apos;s lock states and transitions. This diagram details every possible lock state a connection can be in as well as every path it can take through the life of a transaction. The diagram is represented in terms of lock states, lock transitions, and transaction life cycles. What you are really looking at in the figure are the lives of transactions in terms of locks.--></p>
          <p>Each state has a corresponding lock with the exception of <code>UNLOCKED</code>. So, you can say a connection <q>has a <code>RESERVED</code> lock</q> or <q>is in the <code>RESERVED</code> state</q> or just <q>is in <code>RESERVED</code></q>, and it all means the same thing. With the exception of <code>UNLOCKED</code>, for a connection to be in a given state it must first obtain the associated lock.</p>
          <p>Every transaction starts at <code>UNLOCKED</code>, <code>RESERVED</code>, or <code>EXCLUSIVE</code>. By default, everything begins in <code>UNLOCKED</code><!--, as you can see in Figure 5-3-->. The locks states<!-- in white—--><code>UNLOCKED</code>, <code>PENDING</code>, <code>SHARED</code>, and <code>RESERVED</code><!--—-->can all exist at the same time between connections in a database. Starting with <code>PENDING</code><!-- in gray-->, however, things become more restrictive. The <!--gray --><code>PENDING</code> state represents the lock being held by a single connection, namely, a writer that wants to get to <code>EXCLUSIVE</code>. Conversely, the <!--white --><code>PENDING</code> state represents a path where connections acquire and release the lock on their way to <code>SHARED</code>. Despite all of these different lock states, every transaction in SQLite boils down to one of two types: transactions that read and transactions that write. That ultimately is what paints the locking picture: readers versus writers and how they get along with each other.</p>

          <h3>Read Transactions</h3>
          <p>To start with, let&apos;s go through the lock process of a select statement. Its path is very simple. A connection that executes a select statement starts a transaction, which goes from <code>UNLOCKED</code> to <code>SHARED</code> and upon commit back to <code>UNLOCKED</code>. End of story.</p>
          <p>Now, out of curiosity, what happens when you execute two statements? What is the lock path then? Well, it depends on whether you are running in autocommit or not. Consider the following example:</p>
          <p>Here, with an explicit <code>begin</code>, the two <code>select</code> commands execute within a single transaction and therefore are executed in the same <code>SHARED</code> state. The first <code>exec()</code> runs, leaving the connection in <code>SHARED</code>, and then the second <code>exec()</code> runs. Finally, the manual commit takes the connection from <code>SHARED</code> back to <code>UNLOCKED</code>. The code&apos;s lock path would be as follows:</p>
          <pre>UNLOCKED → PENDING → SHARED → UNLOCKED</pre>
          <p>Now consider the case where there are no <code>begin</code> and <code>commit</code> lines in the example. Then the two <code>select</code> commands run in autocommit mode. They will therefore go through the entire path independently. The lock path for the code now would be as follows:</p>
          <pre>UNLOCKED → PENDING → SHARED → UNLOCKED → PENDING → SHARED → UNLOCKED</pre>
          <p>Since the code is just reading data, it may not make much of a difference, but it does have to go through twice the file locks in autocommit mode than it does otherwise. And, as you will see, a writer could sneak in between the two select commands and modify the database between <code>exec() calls</code>, so you can&apos;t be sure that the two commands will return the same results. With <code>begin..commit</code>, on the other hand, they are guaranteed to be identical in their results.</p>

          <h3>Write Transactions</h3>
          <p>Now let&apos;s consider a statement that writes to the database, such as an <code>update</code>. First, the connection has to follow the same path as <code>select</code> and get to <code>SHARED</code>. Every operation—read or write—has to start by going through <code>UNLOCKED →PENDING → SHARED</code>. <code>PENDING</code>, as you will soon see, is a gateway lock.</p>

            <h4>The Reserved State</h4>
            <p>The moment the connection tries to write anything to the database, it has to go from <code>SHARED</code> to <code>RESERVED</code>. If it gets the <code>RESERVED</code> lock, then it is ready to start making modifications. Even though the connection cannot actually modify the database at this point, it can store modifications in a localized memory cache inside the pager, called the <dfn>page cache</dfn>, mentioned earlier. This cache is the same cache you configure with the <code>cache_size</code> pragma<!--, as described in Chapter 4-->.</p>
            <p>When the connection enters <code>RESERVED</code>, the pager initializes the rollback journal. This is a file <!--(shown in Figure 5-1) -->that is used in rollbacks and crash recovery. Specifically, it holds the database pages needed to restore the database to its original state before the transaction. These database pages are put there by the pager when the B-tree modifies a page. In this example, for every record the <code>update</code> command modifies, the pager takes the database page associated with the <em>original</em> record and copies it out to the journal. The journal then holds some of the contents of the database before the transaction. Therefore, all the pager has to do in order to undo any transaction is to simply copy the contents in the journal back into the database file. Then the database is restored to its state before the transaction.</p>
            <p>In the <code>RESERVED</code> state, there are actually three sets of pages that the pager manages: modified pages, unmodified pages, and journal pages. Modified pages are just that—pages containing records that the B-tree has changed. These are stored in the page cache. Unmodified pages are pages the B-tree read but did not change. These are a product of commands such as <code>select</code>. Finally, there are journal pages, which are the original versions of modified pages. These are not stored in the page cache but rather written to the journal before the B-tree modifies a page.</p>
            <p>Because of the page cache, a writing connection can indeed get real work done in the <code>RESERVED</code> state without interfering with other (reading) connections. Thus, SQLite can effectively have multiple readers and one writer both working on the same database at the same time. The only catch is that the writing connection has to store its modifications in its page cache, not in the database file. Note also that there can be only one connection in <code>RESERVED</code> or <code>EXCLUSIVE</code> for a given database at a given time—multiple readers but only one writer.</p>

            <h4>The Pending State</h4>
            <p>When the connection finishes making changes for the update and the time comes to commit the transaction, the pager begins the process of entering the <code>EXCLUSIVE</code> state. <!--You already know how this works from Chapter 4, but we will repeat it for the sake of completeness. -->From the <code>RESERVED</code> state, the pager tries to get a <code>PENDING</code> lock. Once it does, it holds onto it, preventing any other connections from getting a <code>PENDING</code> lock. Remember we told you that <code>PENDING</code> was a gateway lock. Now you see why. Since the writer is holding onto the <code>PENDING</code> lock, nobody else can get to <code>SHARED</code> from <code>UNLOCKED</code> anymore. The result is that no new connections can enter the database: no new readers, no new writers. This <code>PENDING</code> state is the attrition phase. The writer is guaranteed that it can wait in line for the database and—as long as everyone behaves properly—get it. Only other sessions that already have <code>SHARED</code> locks can continue to work as normal. In <code>PENDING</code>, the writer waits for these connections to finish and release their locks. What&apos;s involved with waiting for locks is a separate issue, which will be addressed shortly in the section <cite>Waiting for Locks</cite>.</p>
            <p>When the other connections release their locks, the database then belongs to the writer. Then, the pager moves from <code>PENDING</code> to <code>EXCLUSIVE</code>.</p>

            <h4>The Exclusive State</h4>
            <p>During <code>EXCLUSIVE</code>, the main job is to flush the modified pages from the page cache to the database file. This is when things get serious, because the pager is going to actually modify the database. It goes about this with extreme caution.</p>
            <p>Before the pager begins writing the modified pages, it first tends to the journal. It checks that the complete contents of the journal have been written to disk. At this point, it is very likely that even though the pager has written pages to the journal file, the operating system has buffered many if not all of them in memory. The pager tells the operating system to literally write all of these pages to the disk. This is where the <code>synchronous</code> pragma comes into play<!--, as described in Chapter 4-->. The method specified by <code>synchronous</code> determines how careful the pager is to ensure that the operating system commits journal pages to disk. The normal setting is to perform a single <q>sync</q> before continuing, telling the operating system to confirm that all buffered journal pages are written to the disk surface. If synchronous is set to <code>FULL</code>, then the pager does two full <q>syncs</q> before proceeding. If synchronous is set to <code>NONE</code>, the pager doesn&apos;t bother with the journal at all (and while it can be 50 times faster, you can kiss transaction durability goodbye).</p>
            <p>The reason that committing the journal to disk is so important is that if the program or system crashes while the pager is writing to the database file, the journal is the only way to restore the database file later. If the journal&apos;s pages weren&apos;t completely written to disk before a system crash, then the database cannot be restored fully to its original state, because the journal pages that were in memory were lost in the crash. In this case, you have an inconsistent database at best and a corrupted one at worse.</p>

            <aside><strong>Caution</strong> Even if you use the most conservative setting for the <code>synchronous</code> pragma, you still may not be guaranteed that the journal is truly committed to disk. This is no fault of SQLite, but rather of certain types of hardware and operating systems. SQLite uses the <code>fsync()</code> system call on Unix and <code>FlushFileBuffers()</code> on Windows to force journal pages to disk. But it has been reported that these functions don&apos;t always work, especially with cheap IDE disks. Apparently, some manufacturers of IDE disks use controller chips that tend to bend the truth about actually committing data to disk. In some cases, the chips cache the data in volatile memory while reporting that they wrote it to the drive surface. Also, there have been (unconfirmed) reports that Windows occasionally ignores <code>FlushFileBuffers()</code>. If you have hardware or software that lies to you, your transactions may not be as durable as you might think.</aside>

            <p>Once the journal is taken care of, the pager then copies all of the modified pages to the database file. What happens next depends on the transaction mode. If, as in this case, the transaction autocommits, then the pager cleans up the journal, clears the page cache, and proceeds from <code>EXCLUSIVE</code> to <code>UNLOCKED</code>. If the transaction does not commit, then the pager continues to hold the <code>EXCLUSIVE</code> lock, and the journal stays in play until either a <code>COMMIT</code> or <code>ROLLBACK</code> is issued.</p>

            <h4>Autocommit and Efficiency</h4>
            <p>With all this in mind, consider what happens with <code>UPDATE</code>s that run in an explicit transaction versus ones that run in autocommit. In autocommit, every command that modifies the database runs in a separate transaction and travels through the following path:</p>
            <pre>UNLOCKED → PENDING → SHARED → RESERVED → PENDING → EXCLUSIVE → UNLOCKED</pre>
            <p>Additionally, each trip through this path involves creating, committing, and clearing out the rollback journal. This all adds up. Although running multiple <code>SELECT</code>s in autocommit mode is perhaps not that big of a deal performance-wise, you should really rethink autocommit mode for frequent writes. And, as mentioned in the <code>SELECT</code> case, when running multiple commands in autocommit, there is nothing stopping another connection from coming along and modifying the database in between commands. If you have two updates that depend on specific values in the database, you should always run them in the same transaction for this reason.</p>

          <aside>
            <h5>Locking And Crash Recovery</h5>
            <p>SQLite&apos;s lock implementation is based on standard file locking. SQLite keeps three different file locks on the database file: a reserved byte, a pending byte, and a shared region.</p>
            <p>Everything starts at the pending byte. To move from <code>UNLOCKED</code> to <code>SHARED</code>, a connection first attempts to get a read-lock on the pending byte. If successful, it gets a read lock on a random byte in the shared region and releases the read lock on the pending byte. To move from <code>SHARED</code> to <code>RESERVED</code>, a connection attempts to obtain a write lock on the reserved byte. To get from <code>RESERVED</code> to <code>EXCLUSIVE</code>, a connection attempts to get a write lock on the pending byte. If successful, this is what causes the attrition process, because it is no longer possible for other connections to get a read lock on the pending byte to enter <code>SHARED</code>. Finally, to get the <code>EXCLUSIVE</code> lock, the connection attempts to get a write lock on the entire shared region. Since the shared region holds read locks by all other active connections, this step guarantees that an <code>EXCLUSIVE</code> lock is granted only after all other <code>SHARED</code> locks are first released.</p>
            <p>SQLite&apos;s crash recovery mechanism uses the reserved byte to determine when a database needs to be restored. Since the journal file and the <code>RESERVED</code> lock go hand in hand, if the pager sees the former without the latter, then something is wrong. Every time the pager opens a database file or tries to fetch a page from the database, it does a simple consistency check. If it finds a journal file but no <code>RESERVED</code> lock on the database, then the process that created the journal file must have crashed, or the system went down. In this case, the journal is called a <dfn>hot journal</dfn>, and the database is potentially in an inconsistent state. To make things right, the journal needs to be <q>played back</q> to restore the database to its original state before the interrupted transaction.</p>
            <p>To start the play back, the pager puts the database into recovery mode. To do this, it goes directly from <code>SHARED</code> to <code>PENDING</code><!-- as shown by the gray line in the illustration (and also in Figure 5-3)-->. This is the only time it ever makes this transition. The reason it skips the reserved lock is twofold. First, by locking the pending byte, it keeps all new connections out of the database. Second, connections that are already in the database (in <code>SHARED</code>) will also see the hot journal the next time they try to access a page. Those connections will attempt to go into recovery mode and replay the journal as well. However, they won&apos;t be able to because the first connection already has the <code>PENDING</code> lock. Thus, by going straight from <code>SHARED</code> to <code>PENDING</code>, the first connection ensures that (1) no new connections can enter the database and (2) active connections in <code>SHARED</code> cannot go into recovery mode. Everyone but the restoring connection is temporarily suspended.</p>
            <p>Basically, a hot journal is an implicit <code>EXCLUSIVE</code> lock. If a writer crashes, no further activity can transpire in the database until some connection restores it. The next pager to access a page will see the hot journal, lock everyone out, and start recovery. If there are no other active connections, then the first program to connect to the database will detect the hot journal and start recovery.</p>
          </aside>

      </section>

      <section>
        <h2>Tuning the Page Cache</h2>
        <p>If we change the previous example and say that it started with a <code>begin</code>, followed by the <code>update</code>, and in the middle of making all those modifications the page cache fills up (runs out of memory), how should SQLite respond? That is, the <code>update</code> results in more modified pages than will fit in the page cache. What happens now?</p>

          <h3>Transitioning to Exclusive</h3>
          <p>The real question is, when exactly does the pager move from <code>RESERVED</code> to <code>EXCLUSIVE</code> and why? There are two scenarios, and you&apos;ve just seen them both. Either the connection reaches the commit point and deliberately enters <code>EXCLUSIVE</code> or the page cache fills up and it has no other option. We just looked at the commit point scenario. So, what happens when the page cache fills up? Put simply, the pager can no longer store any more modified pages and therefore can no longer do any work. It is forced to move into <code>EXCLUSIVE</code> in order to continue. In reality, this is not entirely true because there is a soft limit and a hard limit.</p>
          <p>The soft limit corresponds to the first time the page cache fills up. At this point, the cache is a mixed bag of modified and unmodified pages. In this case, the pager tries to clean out the page cache. It goes through the cache page by page looking for unmodified pages and clearing them out. Once it does that, it can sputter along with what memory has freed up until the cache fills up again. It repeats the process until the cache is completely made up of modified pages. And that is that hard limit. At this point, the pager has no other recourse but to proceed into <code>EXCLUSIVE</code>.</p>
          <p>The <code>RESERVED</code> state, then, is where the <code>cache_size</code> pragma makes a difference. <!--Just as explained in Chapter 4, --><code>cache_size</code> controls the size of the page cache. The bigger the page cache, the more modified pages the pager can store, and the more work the connection can do before having to enter <code>EXCLUSIVE</code>. Also, as mentioned, by doing all the database work in <code>RESERVED</code>, you minimize the time in <code>EXCLUSIVE</code>. If you get all your work done in <code>RESERVED</code>, then <code>EXCLUSIVE</code> is held only long enough to flush modified pages to disk—not compile more queries and process more results and then write to disk. Doing the processing in <code>RESERVED</code> can significantly increase overall concurrency. Ideally, if you have a large transaction or a congested database and you can spare the memory, try to ensure that your cache size is large enough to hold your connection in <code>RESERVED</code> as long as possible.</p>

          <h3>Sizing the Page Cache</h3>
          <p>So, how do you determine what the cache size should be? It depends on what you are doing. Say that you want to update every record in the <var>episodes</var> table. In this case, you know that every page in the table will be modified. Therefore, you figure out how many pages are in <var>episodes</var> and adjust the cache size accordingly. You can get all the information you need on episodes using <code>sqlite3_analyzer</code>. For each table, it will dump detailed statistics, including the total page count. For example, if you run it on the foods database, you get the following information about episodes:</p>
          <samp>Percentage of total database.......... 20.0%
Number of entries..................... 181
Bytes of storage consumed............. 5120
Bytes of payload...................... 3229
Average payload per entry............. 17.84
Average unused bytes per entry........ 5.79
Average fanout........................ 4.00
Maximum payload per entry............. 38
Entries that use overflow............. 0
Index pages used...................... 1
Primary pages used.................... 4
Overflow pages used................... 0
Total pages used...................... 5
Unused bytes on index pages........... 990
Unused bytes on primary pages......... 58
Unused bytes on overflow pages........ 0
Unused bytes on all pages............. 1048</samp>
          <p>The total page count is 5. But of those, only 4 pages of actual table are used—1 page is an index. Since the default cache size is 2,000 pages, you have nothing to worry about. There are about 400 records in <var>episodes</var>, which means there are about 100 records per page. You wouldn&apos;t have to worry about adjusting the page cache before updating every record unless there were at least 196,000 rows in episodes. And remember, you would only need to do this in environments where there are other connections using the database and concurrency is an issue. If you are the only one using the database, then it really wouldn&apos;t matter.</p>

      </section>

      <section>
        <h2>Waiting for Locks</h2>
        <p>We talked earlier about the pager waiting to go from <code>PENDING</code> to <code>EXCLUSIVE</code>. What exactly is involved with waiting on a lock? First, any call to <code>exec()</code> or <code>step()</code> can involve waiting on a lock. Whenever SQLite encounters a situation where it can&apos;t get a lock, the default behavior is to return <code>Delete SQLITE_BUSY</code> to the function that caused it to seek the lock. Regardless of the command you execute, you can potentially encounter <code>SQLITE_BUSY</code>. <code>SELECT</code> commands, as you know by now, can fail to get a <code>SHARED</code> lock if a writer is pending or writing. The simple thing to do when you get <code>SQLITE_BUSY</code> is to just retry the call. However, we will see shortly that this is not always the best course of action.</p>

          <h3>Using a Busy Handler</h3>
          <p>Instead of just retrying the call over and over, you can use a busy handler. Rather than having the API return <code>SQLITE_BUSY</code> if a connection cannot get a lock, you can get it to call the busy handler instead.</p>
          <p>A busy handler is a function you create that kills time or does whatever else you want it to do—it can send spam to your mother-in-law for all SQLite cares. It&apos;s just going to get called when SQLite can&apos;t get a lock. The only thing the busy handler has to do is provide a return value, telling SQLite what to do next. By convention, if the handler returns true, then SQLite will continue to try for the lock. If it returns false, SQLite will then return <code>SQLITE_BUSY</code> to the function requesting the lock. Consider the following example:</p>
          <pre>counter = 1
def busy()
  counter = counter + 1
  if counter == 2
    return 0
  end

  spam_mother_in_law(100)
  return 1
end

db.busy_handler(busy)
stmt = db.prepare('select * from episodes;')
stmt.step()
stmt.finalize()</pre>
          <p>The implementation of spam_mother_in_law() is left as an exercise for the reader.</p>
          <p>The <code>step()</code> function has to get a <code>SHARED</code> lock on the database to perform the <code>select</code>. However, say there is a writer active. Normally, <code>step()</code> would return <code>SQLITE_BUSY</code>. However, in this case it doesn&apos;t. The pager (which is one that deals with locks) calls the <code>busy()</code> function instead, because it has been registered as the busy handler. <code>busy()</code> increments a counter, forwards your mother-in-law 100 random messages from your spam folder, and returns 1, which the pager interprets as true—keep trying to get the lock. The pager then tries again to get the <code>SHARED</code> lock. Say the database is still locked. The pager calls the busy handler again. Only this time, <code>busy()</code> returns 0, which the pager interprets as false. In this case, rather than retrying the lock, the pager sends <code>SQLITE_BUSY</code> up the stack, and that&apos;s what <code>step()</code> ends up returning.</p>
          <p>If you just want to kill time waiting for a lock, you don&apos;t have to write your own busy handler. The SQLite API has one for you. It is a simple busy handler that sleeps for a given period of time waiting for a lock. In the API, the function is called <code>sqlite3_busy_timeout()</code>, and it is supported by some extension libraries. You can essentially say <q>try sleeping for 10 seconds when you can&apos;t get a lock,</q> and the pager will do that for you. If it sleeps for 10 seconds and still can&apos;t get the lock, then it will return <code>SQLITE_BUSY</code>.</p>

          <h3>Using the Right Transaction</h3>
          <p>Let&apos;s consider the previous example again, but this time the command is an <code>update</code> rather than a <code>select</code>. What does <code>SQLITE_BUSY</code> actually mean now? In select, it just means, <q>I can&apos;t get a <code>SHARED</code> lock.</q> But what does is mean for an <code>update</code>? The truth is, you don&apos;t really know what it means. <code>SQLITE_BUSY</code> could mean that the connection failed to get a <code>SHARED</code> lock because there is a writer pending. It could also mean that it got a <code>SHARED</code> lock but couldn&apos;t get to <code>RESERVED</code>. The point is you don&apos;t know the state of the database or the state of your connection for that matter. In autocommit mode, <code>SQLITE_BUSY</code> for a write operation is completely indeterminate. So, what do you do next? Should you just keep calling <code>step()</code> over and over until the command goes through?</p>
          <p>Here&apos;s the thing to think about. Suppose <code>SQLITE_BUSY</code> was the result of you getting a <code>SHARED</code> lock but not <code>RESERVED</code>, and now you are holding up a connection in <code>RESERVED</code> from getting to <code>EXCLUSIVE</code>. Again, you don&apos;t know the state of the database. And just using a brute-force method to push your transaction through is not necessarily going to work, for you or any other connection. If you just keep calling <code>step()</code>, you are just going to butt heads with the connection that has the <code>RESERVED</code> lock, and if neither of you backs down, you&apos;ll deadlock.</p>

          <aside><strong>Note:</strong> SQLite tries to help with deadlock prevention in this particular scenario by ignoring the busy handler of the offending connection. The <code>SHARED</code> connection&apos;s busy handler will not be invoked if it is preventing a <code>RESERVED</code> connection from proceeding. However, it is up to the code to get the hint. The code can still just repeatedly call <code>step()</code> over and over, in which case there is nothing more SQLite can do to help.</aside>

          <p>Since you know you want to write to the database, then you need to start by issuing <code>begin IMMEDIATE</code>. If you get a <code>SQLITE_BUSY</code>, then at least you know what state you&apos;re in. You know you can safely keep trying without holding up another connection. And once you finally do succeed, you know what state you are in then as well—<code>RESERVED</code>. Now you can use brute force if you have to because you are the one in the right. If you start with a <code>begin exclusive</code>, on the other hand, then you are assured that you won&apos;t have any busy conditions to deal with at all. Just remember that in this case you are doing your work in <code>EXCLUSIVE</code>, which is not as good for concurrency as doing the work in <code>RESERVED</code>.</p>

          <aside>
            <h5>Locks and Network File Systems</h5>
            <p>At this point, you should have a good appreciation for what can go wrong when a database is shared over a network file system. SQLite handles concurrency by placing file locks on the database file. It is very important that these locks be both set and released at the right times. SQLite is completely dependent on the file system to manage locks correctly for concurrent use. SQLite uses the same locking mechanisms regardless of whether it is running on a normal file system or network file system. It uses POSIX advisory locks on Unix, Linux, and OS X, and the <code>LockFile()</code>, <code>LockFileEx()</code>, and <code>UnlockFile()</code> system calls on Windows. These calls are standard system calls and work correctly on normal file systems. It is the network file system&apos;s job to emulate a normal file system. And unfortunately, this doesn&apos;t always work correctly with some implementations. And even if the network file system works correctly, there still other things to consider.</p>
            <p>Take NFS, for example. It&apos;s a great network file system. However, many original NFS implementations were known to have buggy or in some cases unimplemented locking. And with a SQLite database, this can cause serious problems. Without locking, two connections can get an <code>EXCLUSIVE</code> lock on the same database and write to it at the same time, leading to an almost certain database corruption. This is not a problem with the NFS protocol in general, but with some implementations of it in particular. Thankfully, most modern implementations of NFS have overcome these issues, and some implementations—such as those from Sun—are now rock-solid.</p>
            <p>NFS can still have issues with locking if one of the clients goes down (taking their database lock with it) and does not come back up. For NFSv3, a locked file would need administrative intervention to clear it. For NFSv4, there would be a timeout period. But how long is the timeout? Thirty seconds? A minute? The real issue is not NFS but specific applications of it. Network file systems, even if perfectly implemented, are not necessarily going to work exactly like a local file system.</p>
            <p>The bottom line is, if you are going to mix concurrency and network file systems, there are many issues to consider, even if you are using the best network file system out there. It&apos;s not as simple as running on a local file system.</p>
          </aside>

      </section>

      <section>
        <h2>Code</h2>
        <p>By now, you have a pretty good picture of the API, transactions, and locks. To finish up, let&apos;s put all three of these things together in the context of your code and consider a few scenarios for which you might want to watch.</p>

          <h3>Using Multiple Connections</h3>
          <p>If you have written code that uses other relational databases, you may have written code that used multiple connections within a single block of code. The classic example is having one connection iterate over a table while another connection modifies records in place.</p>
          <p>In SQLite, using multiple connections in the same block of code can cause problems. You have to be careful of how you go about it. Consider the following example:</p>
          <pre>c1 = open('foods.db')
c2 = open('foods.db')

stmt = c1.prepare('select * from episodes')

while stmt.step()
  print stmt.column('name')
  c2.exec('update episodes set &lt;some columns, criteria, etc.&gt;)
end

stmt.finalize()

c1.close()
c2.close()</pre>
          <p>We bet you can easily spot the problem here. In the while loop, <var>c2</var> attempts an update, while <var>c1</var> has a <code>SHARED</code> lock open. That <code>SHARED</code> lock won&apos;t be released until <code>stmt</code> is finalized after the while loop.</p>
          <p>Therefore, it is impossible to write to the database within the <code>while</code> loop. Either the updates will silently fail, or if you have a busy handler, then it will only delay the program. The best thing to do here is to use one connection for the job and to run it under a single <code>begin immediate</code> transaction. The new version might be as follows:</p>

          <pre>c1 = open('foods.db')

# Keep trying until we get it
while c1.exec('begin immediate') != SQLITE_SUCCESS
end

stmt = c1.prepare('select * from episodes')
while stmt.step()
  print stmt.column('name')
  c1.exec('update episodes set &lt;some columns, criteria, etc.&gt;)
end

stmt.finalize()

c1.exec('commit')
c1.close()</pre>
          <p>In cases like this, you should use statements from a single connection for reading or writing. Then you won&apos;t have to worry about database locks causing problems. However, as it turns out, this particular example still won&apos;t work. If you are iterating over a table with one statement and updating it with another, there is an additional locking issue that you need to know about as well, which we&apos;ll cover next.</p>

          <h3>The Importance of Finalizing</h3>
          <p>A common gotcha in processing select statements is the failure to realize that the <code>SHARED</code> lock is not necessarily released until <code>finalize()</code> (or <code>reset()</code>) is called—well, most of the time. Consider the following example:</p>
          <pre>stmt = c1.prepare('select * from episodes')

while stmt.step()
  print stmt.column('name')
end

c2.exec('begin immediate; update episodes set ...; commit;')

stmt.finalize()</pre>
          <p>Although you should never do this in practice, you might end up doing it anyway by accident simply because you can get away with it. If you write the equivalent of this program in the C API, it will actually work. Even though <code>finalize()</code> has not been called, the second connection can modify the database without any problem. Before we tell you why, take a look at the next example:</p>
          <pre>c1 = open('foods.db')
c2 = open('foods.db')

stmt = c1.prepare('select * from episodes')

stmt.step()
stmt.step()
stmt.step()

c2.exec('begin immediate; update episodes set ...; commit;')

stmt.finalize()</pre>
          <p>Let&apos;s say that episodes has 100 records. And the program stepped through only three of them. What happens here? The second connection will get <code>SQLITE_BUSY</code>.</p>
          <p>In the first example, SQLite released the <code>SHARED</code> lock when the statement reached the end of the result set. That is, in the final call to <code>step()</code>, where the API returns <code>SQLITE_DONE</code>, the VDBE encountered the <code>Close</code> instruction, and SQLite closed the cursor and dropped the <code>SHARED</code> lock. Thus, <var>c2</var> was able to push its insert through even though <var>c1</var> had not called <code>finalize()</code>.</p>
          <p>In the second case, the statement had not reached the end of the set. The next call to <code>step()</code> would have returned <code>SQLITE_RESULT</code>, which means there are more rows in the results set and that the <code>SHARED</code> lock is still active. Thus, <var>c2</var> could not get the insert through this time because of the <code>SHARED</code> lock from <var>c1</var>.</p>
          <p>The moral of the story is don&apos;t do this, even though sometimes you can. Always call <code>finalize()</code> or <code>reset()</code> before you write with another connection. The other thing to remember is that in autocommit mode <code>step()</code> and <code>finalize()</code> are more or less transaction and lock boundaries. They start and end transactions. They acquire and release locks. You should be very careful about what you do with other connections in between these functions.</p>

          <h3>Shared Cache Mode</h3>
          <p>Now that you are clear on the concurrency rules, it&apos;s time for some new confusion. SQLite offers an alternative concurrency model called <dfn>shared cache mode</dfn>, which relates to how connections can operate within individual threads.</p>
          <p>In shared cache mode, a thread can create multiple connections that share the same page cache. Furthermore, this group of connections can have multiple readers and a single writer (in <code>EXCLUSIVE</code>) working on the same database at the same time. The catch is that these connections cannot be shared across threads—they are strictly limited to the thread (running specifically in shared cache mode) that created them. Furthermore, writers and readers have to be prepared to handle a special condition involving table locks.</p>
          <p>When readers read tables, SQLite automatically puts table locks on them. This prevents writers from modifying those tables. If a writer tries to modify a read-locked table, it will get <code>SQLITE_LOCKED</code>. The same logic applies to readers trying to read from write-locked tables. However, in this latter case, readers can still go ahead and read tables that are being modified by a writer if they run in read-uncommitted mode, which is enabled by the <code>read_uncommitted</code> pragma. In this case, SQLite does not place read locks on the tables read by these readers. As a result, these readers don&apos;t interfere with writers at all. However, these readers can get inconsistent query results, because a writer can modify tables as the readers read them. This is similar to the <q>dirty read</q> concept you might have seen in other relational databases.</p>
          <p>Shared cache mode is designed for embedded servers that need to conserve memory and have slightly higher concurrency under certain conditions.<!-- More information on using it with the C API can be found in Chapter 6.--></p>

      </section>

    </main>

  </body>

</html>
