<!DOCTYPE html>
<html>
  <head>
    <title>Digital Subconscious</title>
    <meta charset="UTF-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <link rel="stylesheet" type="text/css" href="stylesheet.en.css"/>
    <!--
    <meta name="keywords" content="KW1, KW2, KW3"/>

    <meta name="author" content="AUTHOR"/>
    <meta name="description" content="A_DESCRIPTION"/>
    <meta name="FIELD_NAME" content="FIELD_VALUE"/>

    <link rel="alternate" hreflang="x-default" href="http://www.example.com/"/>
    <link rel="alternate" hreflang="es" href="http://es.example.com/"/>
    <link rel="alternate" hreflang="de" href="http://de.example.com/"/>

    <link rel="author" href="https://plus.google.com/ExampleProfile"/>
    <link rel="license" href="https://creativecommons.org/licenses/by/4.0/"/>
    -->
  </head>
  <body lang="en" class="computing">
    <nav>
    <!--
      <p><a href="A_PAGE.html">LINK_TEXT</a></p>
      <p><a href="ANOTHER_PAGE.html">LINK_TEXT</a></p>
      <p><a rel="prev" href="PREVIOUS_PAGE.html">LINK_TEXT</a></p>
      <p><a rel="next" href="NEXT_PAGE.html">LINK_TEXT</a></p>
      -->
      <p><a href="ann.html">Artificial Neural Networks</a></p>
      <p><a href="machine_learning.html">Machine Learning</a></p>
      <p><a href="computing.html">Computer Science</a></p>
    </nav>

    <main>
      <h1>Digital Subconscious</h1>
      <p>Because neural nets essentially program themselves, however, they often learn enigmatic rules that no human can fully understand. Sometimes it is very difficult to find out why a neural net made a particular decision.</p>
      <p>When Google&apos;s AlphaGo neural net played go champion Lee Sedol in Seoul, it made a move that flummoxed everyone watching, even Sedol. We still can&apos;t explain it, even though in theory we could look under the hood and review every weight in every node in AlphaGo&apos;s artificial brain, but even a programmer would not glean much from these numbers because their purpose (what drives a neural net to make a decision) is encoded in the billions of diffuse connections between nodes.</p>
      <p>Many experts find this opacity worrying. It doesn&apos;t matter much in the game of go, but imagine a driverless car that has a fatal accident. It&apos;s simply not acceptable to say to an investigator or a judge, <q>We just don&apos;t understand why the car did that.</q>. What if an autonomous drone strikes a school? Or a loan-evaluation program disproportionally denies applications from minorities?</p>
    </main>

  </body>

</html>
