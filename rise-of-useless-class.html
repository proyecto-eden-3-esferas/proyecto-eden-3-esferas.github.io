<!DOCTYPE html>
<html>
  <head>
    <title>Rise of the Useless Class</title>
    <meta charset="UTF-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <link rel="stylesheet" type="text/css" href="stylesheet.en.css"/>
    <!--
    <meta name="keywords" content="KW1, KW2, KW3"/>

    <meta name="author" content="AUTHOR"/>
    <meta name="description" content="A_DESCRIPTION"/>
    <meta name="FIELD_NAME" content="FIELD_VALUE"/>

    <link rel="alternate" hreflang="x-default" href="http://www.example.com/"/>
    <link rel="alternate" hreflang="es" href="http://es.example.com/"/>
    <link rel="alternate" hreflang="de" href="http://de.example.com/"/>

    <link rel="author" href="https://plus.google.com/ExampleProfile"/>
    <link rel="license" href="https://creativecommons.org/licenses/by/4.0/"/>
    -->
  </head>
  <body lang="en">
    <nav>
    <!--
      <div>
        <p><a href="TechnicalStandard.html">Technical Standard</a></p>
        <p><a href="diagram.html">Diagrams and Schematics</a></p>
        <p><a href="Simulation-and-Its-Discontents_by-Sherry-Turkle.html">Simulation and Its Discontents, by Sherry Turkle</a></p>
      </div>
      -->
      <div>
        <p><a rel="prev" href="society.html">Society</a></p>
        <p><a            href="specialization.html">Specialization</a></p>
        <p><a            href="end-of-normal.html">The End of Normal: The Great Crisis and the Future of Growth</a>, by James K. Galbraith</p>
      </div>
      <div>
        <p><a            href="population.html">Population: Force by Numbers</a></p>
        <p><a            href="consumariat.html">The Consumariat: devoted to consumtion</a></p>
        <p><a rel="next" href="bullshit-jobs.html">Bullshit Jobs: A Theory - David Graeber</a></p>
      </div>
    </nav>

    <main>

      <blockquote>Historian Yuval Noah Harari offers a bracing prediction: just as mass industrialization created the working class, the AI revolution will create a new unworking class.</blockquote>

      <h1>The Rise of the Useless Class</h1>
      <p>The most important question in 21st-century economics may well be: What should we do with all the superfluous people, once we have highly intelligent non-conscious algorithms that can do almost everything better than humans?</p>
      <p>This is not an entirely new question. People have long feared that mechanization might cause mass unemployment. This never happened, because as old professions became obsolete, new professions evolved, and there was always something humans could do better than machines. Yet this is not a law of nature, and nothing guarantees it will continue to be like that in the future. The idea that humans will always have a unique ability beyond the reach of non-conscious algorithms is just wishful thinking. The current scientific answer to this pipe dream can be summarized in three simple principles:</p>
      <ol>
        <li>Organisms are algorithms. Every animal — including Homo sapiens — is an assemblage of organic algorithms shaped by natural selection over millions of years of evolution.</li>
        <li>Algorithmic calculations are not affected by the materials from which the calculator is built. Whether an abacus is made of wood, iron or plastic, two beads plus two beads equals four beads.</li>
        <li>Hence, there is no reason to think that organic algorithms can do things that non-organic algorithms will never be able to replicate or surpass. As long as the calculations remain valid, what does it matter whether the algorithms are manifested in carbon or silicon?</li>
      </ol>
      <p>True, at present there are numerous things that organic algorithms do better than non-organic ones, and experts have repeatedly declared that some things will <q>for ever</q> remain beyond the reach of non-organic algorithms. But it turns out that <q>for ever</q> often means no more than a decade or two. Until a short time ago, facial recognition was a favorite example of something that babies accomplish easily but which escaped even the most powerful computers. Today, facial-recognition programs are able to identify people far more efficiently and quickly than humans can.</p>
      <p>In 2004, professor Frank Levy from MIT and professor Richard Murnane from Harvard published research on the job market, listing those professions most likely to undergo automation. Truck driving was given as an example of a job that could not possibly be automated in the foreseeable future. A mere 10 years later, Google and Tesla can not only imagine this, but are actually making it happen.</p>
      <aside>99 percent of human qualities and abilities are simply redundant for the performance of most modern jobs.</aside>
      <p>In fact, as time goes by, it becomes easier and easier to replace humans with computer algorithms, not merely because the algorithms are getting smarter, but also because humans are professionalizing. Ancient hunter-gatherers mastered a very wide variety of skills in order to survive, which is why it would be immensely difficult to design a robotic hunter-gatherer. Such a robot would have to know how to prepare spear points from flint stones, find edible mushrooms in a forest, track down a mammoth, coordinate a charge with a dozen other hunters and use medicinal herbs to bandage any wounds. However, a taxi driver or a cardiologist specializes in a much narrower niche than a hunter-gatherer, which makes it easier to replace them with AI. AI is nowhere near human-like existence, but 99 percent of human qualities and abilities are simply redundant for the performance of most modern jobs. For AI to squeeze humans out of the job market it need only outperform us in the specific abilities a particular profession demands.</p>
      <p>As algorithms push humans out of the job market, wealth and power might become concentrated in the hands of the tiny elite that owns the all-powerful algorithms, creating unprecedented social and political inequality. Alternatively, the algorithms might themselves become the owners. Human law already recognizes intersubjective entities like corporations and nations as <q>legal persons.</q> Though Toyota or Argentina has neither a body nor a mind, they are subject to international laws, they can own land and money, and they can sue and be sued in court. We might soon grant similar status to algorithms. An algorithm could then own a transportation empire or a venture-capital fund without having to obey the wishes of any human master. Before dismissing the idea, remember that most of our planet is already legally owned by non-human intersubjective entities, namely nations and corporations. Indeed, 5,000 years ago much of Sumer was owned by imaginary gods such as Enki and Inanna. If gods can possess land and employ people, why not algorithms?</p>
      <p>So what will people do? Art is often said to provide us with our ultimate (and uniquely human) sanctuary. In a world where computers have replaced doctors, drivers, teachers and even landlords, would everyone become an artist? Yet it is hard to see why artistic creation would be safe from the algorithms. According to the life sciences, art is not the product of some enchanted spirit or metaphysical soul, but rather of organic algorithms recognizing mathematical patterns. If so, there is no reason why non-organic algorithms couldn&apos;t master it.</p>
      <aside>There are some safe jobs: the likelihood that algorithms will displace archaeologists is only 0.7 percent.</aside>
      <p>In the 19th century the Industrial Revolution created a huge urban proletariat, and socialism spread because no other creed managed to answer the unprecedented needs, hopes and fears of this new working class. Liberalism eventually defeated socialism only by adopting the best parts of the socialist program. In the 21st century we might witness the creation of a massive new unworking class: people devoid of any economic, political or even artistic value, who contribute nothing to the prosperity, power and glory of society. This <q>useless class</q> will not merely be unemployed — it will be unemployable.</p>
      <p>In September 2013, two Oxford researchers, Carl Benedikt Frey and Michael A. Osborne, published <cite>The Future of Employment,</cite> in which they surveyed the likelihood of different professions being taken over by computer algorithms within the next 20 years, and they estimated that 47 percent of US jobs are at high risk. For example, there is a 99 percent probability that by 2033 human telemarketers and insurance underwriters will lose their jobs to algorithms. There is a 98 percent probability that the same will happen to sports referees. Cashiers — 97 percent. Chefs — 96 percent. Waiters — 94 percent. Paralegals — 94 percent. Tour guides — 91 percent. Bakers — 89 percent. Bus drivers — 89 percent. Construction laborers — 88 percent. Veterinary assistants — 86 percent. Security guards — 84 percent. Sailors — 83 percent. Bartenders — 77 percent. Archivists — 76 percent. Carpenters — 72 percent. Lifeguards — 67 percent. There are, of course, some safe jobs. The likelihood that computer algorithms will displace archaeologists by 2033 is only 0.7 percent, because their job requires highly sophisticated types of pattern recognition and doesn&apos;t produce huge profits and it is improbable that corporations or government will make the necessary investment to automate archaeology within the next 20 years.</p>
      <aside>Most of what kids currently learn at school will probably be irrelevant by the time they are 40.</aside>
      <p>Of course, by 2033 many new professions are likely to appear — for example, virtual-world designers. But such professions will probably require much more creativity and flexibility than current run-of-the-mill jobs, and it is unclear whether 40-year-old cashiers or insurance agents will be able to reinvent themselves as virtual world designers (try to imagine a virtual world created by an insurance agent!). And even if they do so, the pace of progress is such that within another decade they might have to reinvent themselves yet again. After all, algorithms might well outperform humans in designing virtual worlds, too. The crucial problem isn&apos;t creating new jobs. The crucial problem is creating new jobs that humans perform better than algorithms.</p>
      <p>Since we do not know how the job market would look in 2030 or 2040, today we have no idea what to teach our kids. Most of what they currently learn at school will probably be irrelevant by the time they are 40. Traditionally, life has been divided into two main parts: a period of learning, followed by a period of working. Very soon this traditional model will become utterly obsolete, and the only way for humans to stay in the game will be to keep learning throughout their lives and to reinvent themselves repeatedly. Many, if not most, humans may be unable to do so.</p>
      <hr/>
      <p>The coming technological bonanza will probably make it feasible to feed and support people even without any effort from their side. But what will keep them occupied and content? One answer might be drugs and computer games. Unnecessary people might spend increasing amounts of time within 3D virtual-reality worlds that would provide them with far more excitement and emotional engagement than the drab reality outside. Yet such a development would deal a mortal blow to the liberal belief in the sacredness of human life and of human experiences. What&apos;s so sacred about useless bums who pass their days devouring artificial experiences?</p>
      <p>Some experts and thinkers, such as Nick Bostrom (TED Talk: <cite><a href="https://www.ted.com/talks/nick_bostrom_what_happens_when_our_computers_get_smarter_than_we_are">What happens when our computers get smarter than we are?</a></cite>), warn that humankind is unlikely to suffer this degradation, because once artificial intelligence surpasses human intelligence, it might simply exterminate humankind. The AI would likely do so either for fear that humankind would turn against it and try to pull its plug, or in pursuit of some unfathomable goal of its own. For it would be extremely difficult for humans to control the motivation of a system smarter than themselves.</p>
      <p>Even preprogramming an AI system with seemingly benign goals might backfire horribly. One popular scenario imagines a corporation designing the first artificial super-intelligence and giving it an innocent test such as calculating pi. Before anyone realizes what is happening, the AI takes over the planet, eliminates the human race, launches a campaign of conquest to the ends of the galaxy, and transforms the entire known universe into a giant supercomputer that for billions upon billions of years calculates pi ever more accurately. After all, this is the divine mission its Creator gave it.</p>
      <hr/>
      <p><i>Excerpted from the new book <cite>Homo Deus: A brief history of tomorrow</cite>, by Yuval Noah Harari. Reprinted by permission of Harper, an imprint of HarperCollins Publishers. © 2017 Yuval Noah Harari.</i></p>
    </main>

  </body>

</html>
